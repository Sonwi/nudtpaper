\chapter{绪论}
过去几年联邦学习（Federated Learning，FL）经历了自提出以来的飞速发展，并迅速成为了人工智能领域的研究热点。
作为一种隐私增强的合作学习方案，以梯度间接泄露原始数据的隐私威胁，仍然阻碍着FL的进一步发展。
如何在改进经典FL算法以适用更多应用场景的同时，保证用户上传梯度的隐私和本地数据的安全，成为了当前学术研究的热点问题。
本章首先介绍FL的基本背景，以及解决其中安全隐私威胁的重要意义，然后阐述本文的主要工作和创新点，最后给出全文的结构。

\section{研究背景与意义} 
%\texttt{PBFL} and \texttt{PPFL-HC} are our schemes to solve the problems!
联邦学习（FL）的概念在2016年首次被Mcmahan等人\cite{mcmahan2017communication}提出，
其核心理念是让不同的参与方将数据保持在本地，通过交换模型更新（参数或者梯度）的方式协同训练一个全局模型，通过避免直接交易数据的方式，提供了一定的隐私保护。
其注重隐私的分布式训练方式迅速得到了发展，并成为了人工智能领域的研究热点\cite{bhagoji2019analyzing}。其蓬勃的发展主要受益于如下三个事实：（1）机器学习和深度学习技术广泛的应用成功落地；（2）大数据时代爆发式的数据增长；（3）全球数据隐私保护法律法规的制定和实施。

机器学习技术广泛而成功的应用是推动FL发展的主要动力。
在过去的几十年里，机器学习技术在各个领域的一些应用中取得了令人瞩目的成就，如自然语言处理\cite{devlin2018bert}、图像处理\cite{zhu2020neural}和生物识别\cite{yin20193d}。其中最有名的应用是AlphaGo\cite{silver2017mastering}。2016年，AlphaGo以4:1的比分成功击败了9段职业棋手；2017年，它继续以3:0的比分成功击败了当时世界排名第一的围棋选手；而现在，它的继任者，自学成才的AlphaZero，被认为是世界上最好的围棋选手。此外，许多其他应用已经被广泛商业化，包括应用于各种电子产品和门禁系统的人脸识别系统。这些成功的机器学习应用为FL的发展铺平了道路。

大数据的爆发式增长导致越来越多数据孤岛（data islands）的出现，进一步推动了FL的发展。
每天都有大量的数据从社交网络、物联网、智能电网、电子商务、医院、银行系统和其他领域产生\cite{hu2016energy}。这种趋势促进了机器学习的发展，但也给传统的机器学习带来了巨大的挑战，因为大数据通常被不同的组织存储在不同的设备中，形成数据孤岛。
例如，典型的数据孤岛就是不同医院持有的患者医疗数据，单个医院的数据在规模和分布上都有局限性，所以无法训练出高质量的模型。在理想的情况下，所有医院可以自由交易数据，联合所有数据进行模型的训练。但是医疗数据包含非常敏感的个人信息，不允许被随意共享。
在隐私问题的限制下，学习一个全局模型对于传统机器学习来说，变得越来越有挑战性。
而FL作为一种新兴的分布式学习范式，正在让人工智能的研究与应用走出数据孤岛的限制。

数据隐私保护的法律规定推动了FL的快速发展。近年来，许多数据泄露事件大大威胁了用户的数据隐私。例如，2019年，亚马逊云服务上超过5.4亿条Facebook用户的记录被曝光\footnote{https://www.upguard.com/breaches/facebook-user-data-leak.}，这引起了严重的社会和法律问题。因此为了保护用户的私人数据，许多法律规定被制定出来，如欧盟的《通用数据保护条例》（General Data Protection Regulation，GDPR）\cite{voigt2017eu}，新加坡的《新加坡个人数据保护法》\cite{chik2013singapore}，以及美国的《加州隐私权利法》\footnote{https://oag.ca.gov/privacy/ccpa.}。这些法规极大地促进了FL的发展，特别是保护隐私的FL。

然而，相关研究\cite{geiping2020inverting, zhu2019deep}表明FL仍然存在隐私泄露的风险。
FL在每轮次的训练中，需要参与方上传由本地数据训练得到的模型更新（模型参数或梯度）。
由于此信息来源于用户原始数据，携带了大量的原始数据的特征。研究\cite{zhu2019deep}表明，半诚实（诚实且好奇，即遵守聚合规则，但尽力推理用户隐私）的聚合服务器可以利用用户上传的梯度，还原部分用户的原始数据（数据重构攻击，Data reconstruction attack），或者根据梯度推断所掌握的记录是否来自于用户的隐私数据（成员推断攻击，Membership inference attack）。
除此之外，FL训练完成之后的全局模型也面临隐私泄露的风险，这种风险与传统机器学习面临的风险一致。
在模型的训练过程中，准确率的提高依赖于对数据样本的规律挖掘。研究\cite{song2017machine}表明，高精度模型的参数可以“记住”更多训练数据的细节。根据这一特性，半诚实服务器可以在完成训练之后，利用获取的全局模型进一步推测用户的隐私数据信息。
因此，直接交易中间参数的FL，其参与方的隐私数据都将面临直接泄露给半诚实服务器的风险，而数据一旦被直接泄露，将会对参与方造成严重的损失。

此外，FL作为分布式协同训练系统，其鲁棒性也面临着恶意参与方的安全威胁。
FL中的参与方可信程度较低，容易被敌对方所控制。
研究\cite{blanchard2017machine}指出，仅有一个参与方被敌对方控制时，也能破坏全局模型向训练目标的收敛，造成全局推理准确率低下。
如果如此脆弱的FL在真实世界中部署，由参与方贡献数据联合训练出来的全局模型，很可能被极少量的恶意参与方（拜占庭节点）劫持，最后得到完全不可用的全局模型。
因此提高FL聚合算法的鲁棒性，识别出恶意参数并降低甚至消除其对全局模型的影响，对FL在真实场景中的落地有着重大意义。

同时，FL中的异质数据分布，给FL带来了新的挑战。尽管经典FL提出的平均线性聚合算法FedAvg \cite{mcmahan2017communication}，在一定程度上可以缓解异质数据分布（即用户间数据分布不一致，non-independent identical distribution data, Non-IID）给全局模型带来的负面影响。但是大量的研究\cite{zhao2018federated}表明，在面对异质数据分布时，FedAvg的准确率下降几乎是不可避免的。
其性能下降的主要原因，是由异质数据分布造成的参与方本地模型权重出现分歧（weight divergence）。
也就是说，由于本地数据分布的异质性，具有相同初始参数的本地模型将收敛为不同的模型，
如果还是使用FedAvg使用平均线性聚合的方式生成一个全局模型，这种权重的分歧将持续增加，导致了模型性能的下降。
而异质数据分布的场景广泛存在于各种机器学习场景和任务中，提升FL在该场景下的联合训练准确率，将进一步拓宽FL的应用场景。

综上所述，FL在人工智能浪潮和大数据爆发式增长的背景下，在保护数据隐私的同时，充分挖掘数据的可用性，成为了解决传统机器学习所面临的数据孤岛问题的前沿方案。
但是其面临的隐私威胁、拜占庭节点造成的安全威胁以及异质数据分布带来的性能下降问题，都在阻碍着FL的进一步发展与应用。
虽然当前学术界已经有了一些针对FL的隐私性和鲁棒性的研究成果，但是在权衡隐私、鲁棒与效率时仍有缺陷。
因此本文以FL面临的隐私威胁和鲁棒性需求为背景，深入分析FL在面对拜占庭节点干扰、异质数据分布影响等复杂场景时，所面临的基本问题和技术难点，以实现高隐私性、高鲁棒性以及高效率为主要目标，提出完善的解决方案，并结合理论分析和真实数据集上的测试，对方案的隐私性、鲁棒性和执行效率进行验证。
通过本文的研究，我们期望可以在保证参与方数据隐私的同时，拓展FL面对拜占庭节点的鲁棒性，提升异质分布数据训练的准确率，为FL在更丰富的场景落地实际的应用打下坚实的基础。

\section{联邦学习中安全隐私问题概述}


\section{本文研究内容和创新点}


\section{论文的组织结构}
