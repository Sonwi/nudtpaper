\chapter{总结与展望}
\section{工作总结}
联邦学习是一种平衡数据隐私和数据可用性的分布式机器学习范式，它允许多个参与方在不共享隐私数据的前提下协同训练一个机器学习模型。它的发展和完善将一个个数据孤岛联合起来，在医疗保健、金融服务、交通运算、工业控制等领域得到了广泛的应用。
然而，联邦学习在展现其应用潜力的同时，潜在的安全隐私威胁仍然阻碍着它的进一步发展。一方面，模型参数携带了用户的数据特征，存在潜在隐私泄露风险，因此需要进一步保证模型参数的\textbf{隐私性}；另一方面，一些具体场景需要对模型参数进行复杂的计算，因此需要保证模型参数的\textbf{可用性}。为此，本文针对两个具体场景，致力于兼顾模型参数的隐私性和可用性。本文的主要研究内容和贡献包括以下两个方面：

（1）提出了一种面向拜占庭容错的模型参数安全聚合技术。针对联邦学习中存在拜占庭用户干扰训练的场景，同时考虑对模型参数的隐私保护，方案实现了在密文上高效过滤恶意参数，保证隐私的同时实现了对拜占庭节点的鲁棒。具体而言，方案首先提出了一种密文计算友好的拜占庭鲁棒聚合算法，再结合多方同态加密构建隐私保护模块，设计了一系列安全计算协议，保证了参数的安全高效聚合。此外，本文对方案进行了详细的理论分析和实验验证，证明了方案在隐私、鲁棒以及效率上的优势。

（2）提出了一种面向异质分布数据的模型参数安全聚合技术。为了提升联邦学习对于异质分布数据的联合训练准确率，同时兼顾对模型参数的隐私保护，方案实现了在密文上的高效安全聚类，从而提升异质分布数据训练性能。具体来说，方案基于扩展性较好的聚类异质联邦学习方案，设计了安全高效的隐私保护计算模块，在此基础上实现了高效的梯度安全聚类。同时，本文还观察到梯度中特征维度的冗余，使用随机降维的方式大幅提升了安全计算效率。此外，本文对方案进行了详尽的理论分析和实验论证，证明了方案在保证数据隐私的前提下，大幅提升了异质分布数据的联合训练准确率。

\section{研究展望}
联邦学习中模型参数的隐私性，需要与复杂场景下的可用性以及计算高效性进行权衡。本文的研究在权衡三者之间取得了一定的成果，但是仍然存在一些问题值得进一步的深入研究。以本文为基础，未来的研究需要进一步解决如下的问题：

（1）本文针对存在拜占庭节点的联邦学习场景提出的隐私保护联邦学习方案，限制于对模型参数的隐私保护和计算的效率性，设计的鲁棒聚合算法较为简单，主要针对是典型的非目标性拜占庭攻击。在后续的工作中，可以进一步完善鲁棒聚合方案，同时辅以高效的安全协议设计，保证高效的同时进一步提升方案的鲁棒性。

（2）本文针对异质分布数据提出的隐私保护联邦学习方案，虽然能够提升异质分布数据的联合训练准确率，但是联邦学习中的异质分布数据问题是一个比较开放的问题，在不同分布场景下不同算法各有优劣。本文的优势在于考虑了模型参数的隐私保护，并可以结合其它针对异质分布数据的研究，进一步提升推理准确率。在以后的研究中，可以针对异质分布数据进行训练算法上的创新，保证隐私的同时进一步提升方案的有效性。

（3）此外，本文设计的方案均需要一个协助运算的辅助服务器，用以权衡数据的隐私性和可用性。受限于全同态上的非线性运算和秘密共享对于多方的需求，多数研究目前还是基于双云模型。在以后的研究中，可以针对单服务器场景的隐私计算进行深入研究，提升密文计算效率，简化方案涉及到的系统模型。
